---
title: "MRR_TP3_Zeyu_CHEN_Clement_VEYSSIERE"
author: "Zeyu CHEN"
date: "2018/11/5"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r , include=TRUE}
tab <- read.table("SAheart.txt",sep = ",",header = TRUE,row.names=1)
tab$famhist <- as.numeric(tab$famhist == "Present")
tab
plot(tab)
```
```{r , include=TRUE}

pairs(tab,pch=22,bg=c("red","blue")[unclass(factor(tab$chd))])
plot(tab$chd~tab$obesity,xlim=c(15,40))
#what can you say on the various joint distribution

```
##A Logistic regression model

###a)
```{r , include=TRUE}
res <- glm(chd ~ .,family  = binomial,data = tab)
#family  = binomial ça veut dire que la variable dépendente appartient à "binomial family"

summary(res)
```

###b)
```{r , include=TRUE}
attributes(res)

#predict.glm(res,newdata = tab,type = "link")
prefull <-predict.glm(res,newdata = tab,type = "response")

Chap<- as.numeric(prefull>0.5) 
Chap

#exp(res$coefficients)
```

##B Logistic regression model

### Confusion matrix TP TN FP FN 

###a 
```{r , include=TRUE}
library(dplyr)
xNew <- as.matrix(select(data.frame(1,tab),-chd))
#xNew
#res$coefficients
nChap <- 1/(1+exp(-xNew%*%res$coefficients))
yChap<- as.numeric(nChap>0.9) 
t <- table(yChap,y=tab$chd)
t
#ou c(0,1)[factor(nChap>0.5)]
```

###b 
```{r , include=TRUE}
t <- table(yChap,y=tab$chd)
t
Taux_FP <- 46/(256+46)
Taux_FN <- 77/(77+83)
Taux_FP
Taux_FN 
performance <- (t[1,1]+t[2,2])/nrow(tab)
performance

```

##K-fold
```{r , include=TRUE}

#Randomly shuffle the data
tab<-tab[sample(nrow(tab)),]

kfold <- function(k)
{
performance <- vector(length = k)
#Create 10 equally size folds
folds <- cut(seq(1,nrow(tab)),breaks=k,labels=FALSE)

#Perform 10 fold cross validation
for(i in 1:k){
  #Segement your data by fold using the which() function 
  testIndexes <- which(folds==i,arr.ind=TRUE)
  testData <- tab[testIndexes,]
  trainData <- tab[-testIndexes,]

  #Use the test and train data partitions however you desire..
  
}

}
par(mfrow=c(1,2))
kfold(10)
kfold(5)

```

###ROC curve
```{r , include=TRUE}
library(ROCR)

prelink <- predict.glm(res,newdata = tab,type = "link")
pre <- prediction(prelink,tab$chd)

#threshold varie de 1 à 0
plot(performance(pre,"sens","spec"))
plot(performance(pre,"tpr","fpr"))
abline(0,1)

#preres <- predict.glm(res,newdata = tab,type = "response")


```

## Model selection

### 1. Statistical approach : forward, backword,stepwise selection

### a.1)
```{r , include=TRUE}
#regression logistique Forward
resall <- glm(chd~.,data=tab,family = binomial)
res0 <- glm(chd~1,data = tab,family = binomial)
resfor<- step(res0,list(upper=resall),direction = 'forward')
```

### a.2)
```{r , include=TRUE}
#regression logistique Backward
resback <- step(res,direction = 'backward')

#print(resback)            
```
### a.3)
```{r , include=TRUE}
#regression logistique StepWise
reswise <- step(res,direction = 'both')

print(reswise)            
```

### b)
```{r , include=TRUE}
library(ROCR)
prelink <- predict.glm(res,newdata = tab,type = "response")
pre <- prediction(prelink,tab$chd)
#threshold varie de 1 à 0
plot(performance(pre,"acc"),col="red",ylim=c(0.3,0.8),xlim=c(0,1))
par(new=TRUE)
prelink <- predict.glm(resfor,newdata =tab,type = "response")
pre <- prediction(prelink,tab$chd)

plot(performance(pre,"acc"),ylim=c(0.3,0.8),xlim=c(0,1))
```
## On dira les deux models sont preques pareil en terme de capacité de prediction

## 2 Logistic regression with l1 or l2 penalizations

```{r , include=TRUE}
library(glmnet)
tab <- read.table("SAheart.txt",sep = ",",header = TRUE,row.names=1)
tab$famhist <- as.numeric(tab$famhist == "Present")

## partitionning
sub <- sample(nrow(tab), 0.8 * nrow(tab))
tabTrain <- tab[sub,]
tabTest <- tab[-sub,]

```
### a)
```{r , include=TRUE}
library(glmnet)
data <- as.matrix(tabTrain[-10])
glmmod <- glmnet(data,as.factor(tabTrain$chd),alpha = 0,family="binomial")
plot(glmmod)
modRidgeDev<- cv.glmnet(data,as.factor(tabTrain$chd),family="binomial",type.measure="deviance",alpha=0)

modRidgeClass<- cv.glmnet(data,as.factor(tabTrain$chd),family="binomial",type.measure="class",alpha=0)

modRidgeMae<- cv.glmnet(data,as.factor(tabTrain$chd),family="binomial",type.measure="mae",alpha=0)

plot(modRidgeDev)
plot(modRidgeClass)
plot(modRidgeMae)


predict(modRidgeDev, as.matrix(tabTest[-10]),type="response", s=modRidgeDev$lambda.min)
coef(modRidgeDev$glmnet.fit)
```

### b)

```{r , include=TRUE}
library(glmnet)
tab <- read.table("SAheart.txt",sep = ",",header = TRUE,row.names=1)
tab$famhist <- as.numeric(tab$famhist == "Present")

data <- as.matrix(tabTrain[-10])
glmmod <- glmnet(data,as.factor(tabTrain$chd),alpha = 1,family="binomial")
plot(glmmod)


modLassoDev<- cv.glmnet(data,as.factor(tabTrain$chd),family="binomial",type.measure="deviance",alpha=1)

modLassoClass<- cv.glmnet(data,as.factor(tabTrain$chd),family="binomial",type.measure="class",alpha=1)

modLassoMae<- cv.glmnet(data,as.factor(tabTrain$chd),family="binomial",type.measure="mae",alpha=1)

plot(modLasso)
plot(modLassoClass)
plot(modLassoMae)

pre <- predict(modLasso, as.matrix(tabTest[-10]),type="response", s=modLasso$lambda.min)
pre
```

##D
```{r , include=TRUE}
#Randomly shuffle the data

tab<-tab[sample(nrow(tab)),]


 #Use the test and train data partitions however you desire..
  preFull <- sum((as.numeric(predict(res,newdata = tab,type = "response")>0.5)-tab$chd)^2)
  preWise<- sum((as.numeric(predict(reswise,newdata = tab,type = "response")>0.5)-tab$chd)^2)
  preRidge <- sum((as.numeric(predict(modRidgeDev,newx =  as.matrix(tab[-10]),s=modLassoMae$lambda.1se,type="response")>0.5)-tab$chd)^2)
  preLasso <- sum((as.numeric(predict(modLassoDev,newx =  as.matrix(tab[-10]),s=modLassoMae$lambda.1se,type="response")>0.5)-tab$chd)^2)

c(preFull,preWise,preRidge,preLasso)



```